{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T02:33:00.697169Z",
     "iopub.status.busy": "2025-11-03T02:33:00.696591Z",
     "iopub.status.idle": "2025-11-03T02:33:18.788971Z",
     "shell.execute_reply": "2025-11-03T02:33:18.788388Z",
     "shell.execute_reply.started": "2025-11-03T02:33:00.697145Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-03 02:33:02.162874: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762137182.378569      37 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762137182.436669      37 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading tokenizers...\n",
      "Tokenizers loaded successfully.\n",
      "Encoder Vocab: 305 | Decoder Vocab: 526\n",
      "Max Seq Lens (Enc/Dec): 7 / 12\n",
      "Loading pre-trained model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762137195.035351      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1762137195.035998      37 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ decoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">134,656</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_inputs      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dec_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_emb (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │     <span style=\"color: #00af00; text-decoration-color: #00af00\">78,080</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">NotEqual</span>)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_gru_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,361,600</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_bi_1        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,476,864</span> │ enc_emb[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_gru_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GRU</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)   │  <span style=\"color: #00af00; text-decoration-color: #00af00\">3,541,248</span> │ decoder_gru_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_bi_2        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)    │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,656,512</span> │ encoder_bi_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ encoder_inputs[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_attention       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)            │                   │            │ encoder_bi_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ enc_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ not_equal_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "│                     │                   │            │ not_equal[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_ctx_dec      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1536</span>)  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ decoder_gru_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ dot_attention[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">526</span>)   │    <span style=\"color: #00af00; text-decoration-color: #00af00\">808,462</span> │ concat_ctx_dec[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ decoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dec_emb (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │    \u001b[38;5;34m134,656\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_inputs      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ dec_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ decoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_emb (\u001b[38;5;33mEmbedding\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │     \u001b[38;5;34m78,080\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ not_equal           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "│ (\u001b[38;5;33mNotEqual\u001b[0m)          │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_gru_1 (\u001b[38;5;33mGRU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m768\u001b[0m)   │  \u001b[38;5;34m2,361,600\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_bi_1        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)    │  \u001b[38;5;34m1,476,864\u001b[0m │ enc_emb[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ decoder_gru_2 (\u001b[38;5;33mGRU\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m768\u001b[0m)   │  \u001b[38;5;34m3,541,248\u001b[0m │ decoder_gru_1[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ encoder_bi_2        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m768\u001b[0m)    │  \u001b[38;5;34m2,656,512\u001b[0m │ encoder_bi_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mBidirectional\u001b[0m)     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ enc_mask (\u001b[38;5;33mLambda\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ encoder_inputs[\u001b[38;5;34m0\u001b[0m… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dot_attention       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m768\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ decoder_gru_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mLambda\u001b[0m)            │                   │            │ encoder_bi_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ enc_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ not_equal_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m… │\n",
       "│                     │                   │            │ not_equal[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concat_ctx_dec      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m1536\u001b[0m)  │          \u001b[38;5;34m0\u001b[0m │ decoder_gru_2[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ dot_attention[\u001b[38;5;34m0\u001b[0m]… │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ final_dense (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m526\u001b[0m)   │    \u001b[38;5;34m808,462\u001b[0m │ concat_ctx_dec[\u001b[38;5;34m0\u001b[0m… │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,172,268</span> (126.54 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,172,268\u001b[0m (126.54 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,057,422</span> (42.18 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,057,422\u001b[0m (42.18 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,114,846</span> (84.36 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22,114,846\u001b[0m (84.36 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully loaded from /kaggle/input/seq2seq-kaggle/tensorflow2/default/1/seq2seq_model.keras\n",
      "\n",
      "--- Setup selesai. Model siap digunakan untuk inferensi. ---\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Skrip ini memuat model Sequence-to-Sequence (Seq2Seq) berarsitektur Encoder-Decoder\n",
    "dengan mekanisme atensi (attention) yang telah dilatih sebelumnya.\n",
    "Model digunakan untuk mendekode atau menghasilkan kalimat dari sekuens masukan\n",
    "menggunakan beam search dengan berbagai penalti dan pascapemrosesan hasil keluaran.\n",
    "\n",
    "Proses utama meliputi:\n",
    "1. Pemuatan model dan tokenizer.\n",
    "2. Definisi fungsi pendukung (loss, attention, masking, dan dekoding).\n",
    "3. Implementasi beam search dengan penalti panjang, repetisi, dan token wajib.\n",
    "4. Pascapemrosesan keluaran untuk menghasilkan kalimat yang bersih dan alami.\n",
    "\"\"\"\n",
    "\n",
    "# --- Inisialisasi Awal ---\n",
    "import os\n",
    "# Mengabaikan log TensorFlow (1 = INFO, 2 = WARNING, 3 = ERROR)\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import warnings\n",
    "# Mengabaikan peringatan dari library\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "import json, re, pickle\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, GRU, Bidirectional, Dense, Concatenate, Lambda, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# --- Konfigurasi Jalur File ---\n",
    "INPUT_DIR = \"/kaggle/input/seq2seq-kaggle/tensorflow2/default/1\"\n",
    "MODEL_PATH = os.path.join(INPUT_DIR, \"seq2seq_model.keras\")\n",
    "TOK_ENC_PATH = os.path.join(INPUT_DIR, \"tokenizer_enc.pkl\")\n",
    "TOK_DEC_PATH = os.path.join(INPUT_DIR, \"tokenizer_dec.pkl\")\n",
    "\n",
    "# --- Hiperparameter Dekoding ---\n",
    "BEAM_WIDTH = 5\n",
    "TOP_K = 5\n",
    "LENGTH_PENALTY_ALPHA = 0.8\n",
    "REPETITION_PENALTY = 1.2\n",
    "NO_REPEAT_NGRAM_SIZE = 3\n",
    "REQUIRED_TOKEN_PENALTY = -100.0\n",
    "\n",
    "# --- Parameter Model Tetap (berdasarkan hasil pelatihan) ---\n",
    "max_enc_len = 7\n",
    "max_dec_len = 12\n",
    "\n",
    "# --- Pemuatan Tokenizer ---\n",
    "print(\"Loading tokenizers...\")\n",
    "try:\n",
    "    with open(TOK_ENC_PATH, \"rb\") as f:\n",
    "        enc_tok = pickle.load(f)\n",
    "    with open(TOK_DEC_PATH, \"rb\") as f:\n",
    "        dec_tok = pickle.load(f)\n",
    "    print(\"Tokenizers loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Tokenizer files not found. Searched in '{INPUT_DIR}'\")\n",
    "    print(\"Pastikan file .pkl ada dan path INPUT_DIR sudah benar.\")\n",
    "    raise\n",
    "\n",
    "# --- Derivasi Informasi dari Tokenizer ---\n",
    "num_enc_tokens = len(enc_tok.word_index) + 1\n",
    "num_dec_tokens = len(dec_tok.word_index) + 1\n",
    "rev_dec_index = {v: k for k, v in dec_tok.word_index.items()}\n",
    "rev_dec_index[0] = \"<pad>\"\n",
    "start_tok = dec_tok.word_index.get(\"<start>\")\n",
    "end_tok = dec_tok.word_index.get(\"<end>\")\n",
    "\n",
    "print(f\"Encoder Vocab: {num_enc_tokens} | Decoder Vocab: {num_dec_tokens}\")\n",
    "print(f\"Max Seq Lens (Enc/Dec): {max_enc_len} / {max_dec_len}\")\n",
    "\n",
    "# --- Fungsi Pendukung untuk Memuat Model ---\n",
    "LABEL_SMOOTH = 0.1  # Nilai label smoothing (harus sama dengan saat pelatihan)\n",
    "\n",
    "def smooth_sparse_cce(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Fungsi loss kustom Sparse Categorical Cross-Entropy dengan label smoothing.\n",
    "    Mengabaikan kontribusi loss dari token padding.\n",
    "    \"\"\"\n",
    "    y_true_squeezed = tf.squeeze(tf.cast(y_true, tf.int32), axis=-1)\n",
    "    y_true_oh = tf.one_hot(y_true_squeezed, depth=num_dec_tokens)\n",
    "    y_true_sm = y_true_oh * (1.0 - LABEL_SMOOTH) + LABEL_SMOOTH / tf.cast(num_dec_tokens, tf.float32)\n",
    "    cce = tf.keras.losses.categorical_crossentropy(y_true_sm, y_pred)\n",
    "    mask = tf.cast(tf.not_equal(y_true_squeezed, 0), tf.float32)\n",
    "    return tf.reduce_sum(cce * mask) / (tf.reduce_sum(mask) + 1e-9)\n",
    "\n",
    "def create_encoder_mask(inputs):\n",
    "    \"\"\"Membuat mask untuk mengabaikan token padding pada input encoder.\"\"\"\n",
    "    return tf.cast(tf.not_equal(inputs, 0), tf.float32)\n",
    "\n",
    "def dot_attention_fn(args):\n",
    "    \"\"\"\n",
    "    Menghitung atensi (dot-product attention) antara keluaran decoder dan encoder.\n",
    "    Menghasilkan vektor konteks sebagai hasil perkalian bobot atensi dengan keluaran encoder.\n",
    "    \"\"\"\n",
    "    dec_out_tensor, enc_out_tensor, enc_mask_tensor = args\n",
    "    scores = tf.matmul(dec_out_tensor, enc_out_tensor, transpose_b=True)\n",
    "    mask = tf.expand_dims(enc_mask_tensor, axis=1)\n",
    "    scores += (1.0 - mask) * -1e9\n",
    "    attn = tf.nn.softmax(scores, axis=-1)\n",
    "    context = tf.matmul(attn, enc_out_tensor)\n",
    "    return context\n",
    "\n",
    "# --- Pemuatan Model Terlatih ---\n",
    "print(\"Loading pre-trained model...\")\n",
    "custom_objects = {\n",
    "    \"smooth_sparse_cce\": smooth_sparse_cce,\n",
    "    \"create_encoder_mask\": create_encoder_mask,\n",
    "    \"dot_attention_fn\": dot_attention_fn\n",
    "}\n",
    "\n",
    "try:\n",
    "    model = tf.keras.models.load_model(MODEL_PATH, custom_objects=custom_objects)\n",
    "    model.summary()\n",
    "    print(f\"Model successfully loaded from {MODEL_PATH}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file not found at '{MODEL_PATH}'\")\n",
    "    print(\"Pastikan file .keras ada dan path INPUT_DIR sudah benar.\")\n",
    "    raise\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while loading the model: {e}\")\n",
    "    raise\n",
    "\n",
    "# --- Fungsi Pascapemrosesan ---\n",
    "def remove_consecutive_duplicates(words):\n",
    "    \"\"\"Menghapus kata duplikat yang muncul secara berurutan.\"\"\"\n",
    "    if not words: return []\n",
    "    output = [words[0]]\n",
    "    for word in words[1:]:\n",
    "        if word != output[-1]:\n",
    "            output.append(word)\n",
    "    return output\n",
    "\n",
    "def remove_nonconsecutive_duplicates(words):\n",
    "    \"\"\"Menghapus kata duplikat yang muncul di posisi berbeda (tidak berurutan).\"\"\"\n",
    "    seen = set()\n",
    "    out = []\n",
    "    for w in words:\n",
    "        if w and w not in seen:\n",
    "            out.append(w)\n",
    "            seen.add(w)\n",
    "    return out\n",
    "\n",
    "def cut_at_first_sentence_end(text):\n",
    "    \"\"\"Memotong kalimat pada tanda baca akhir pertama (., !, ?).\"\"\"\n",
    "    match = re.search(r'[.!?]', text)\n",
    "    return text[:match.end()] if match else text\n",
    "\n",
    "def post_process_sequence(token_ids):\n",
    "    \"\"\"\n",
    "    Mengubah daftar token menjadi teks yang bersih:\n",
    "    - Menghapus token khusus (<start>, <end>, <pad>)\n",
    "    - Menghapus duplikat kata\n",
    "    - Membersihkan spasi dan memotong pada akhir kalimat\n",
    "    \"\"\"\n",
    "    words = [rev_dec_index.get(tok, \"\") for tok in token_ids if tok not in (start_tok, end_tok, 0)]\n",
    "    words = remove_consecutive_duplicates(words)\n",
    "    words = remove_nonconsecutive_duplicates(words)\n",
    "    text = \" \".join(words).strip()\n",
    "    text = cut_at_first_sentence_end(text)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "# --- Fungsi Pendukung Beam Search ---\n",
    "def get_required_token_ids(input_text):\n",
    "    \"\"\"Mengambil token wajib (yang berasal dari input) untuk penalti jika hilang di keluaran.\"\"\"\n",
    "    words = set(re.sub(r'[^\\w\\s]', '', input_text.lower()).split())\n",
    "    return {dec_tok.word_index[w] for w in words if w in dec_tok.word_index}\n",
    "\n",
    "def length_penalty(length, alpha=LENGTH_PENALTY_ALPHA):\n",
    "    \"\"\"Menghitung penalti panjang agar kalimat tidak terlalu pendek atau panjang.\"\"\"\n",
    "    return ((5.0 + length) / 6.0) ** alpha\n",
    "\n",
    "# --- Implementasi Beam Search Decoder ---\n",
    "def beam_search_decoder(input_text, beam_width=BEAM_WIDTH, max_out_len=None, top_k=TOP_K):\n",
    "    \"\"\"\n",
    "    Melakukan proses decoding menggunakan beam search dengan penalti panjang, repetisi, dan token wajib.\n",
    "\n",
    "    Args:\n",
    "        input_text (str): Kalimat masukan (sekuens kata kunci).\n",
    "        beam_width (int): Jumlah beam aktif di setiap langkah.\n",
    "        max_out_len (int): Panjang maksimum keluaran.\n",
    "        top_k (int): Jumlah token terbaik yang dipertimbangkan di setiap langkah.\n",
    "\n",
    "    Returns:\n",
    "        str: Kalimat keluaran hasil dekoding yang telah diproses.\n",
    "    \"\"\"\n",
    "    if max_out_len is None:\n",
    "        max_out_len = min(max_dec_len, int(len(input_text.split()) * 2.5 + 5))\n",
    "\n",
    "    seq_enc = pad_sequences(enc_tok.texts_to_sequences([input_text]), maxlen=max_enc_len, padding=\"post\")\n",
    "    required_ids = get_required_token_ids(input_text)\n",
    "    beams = [([start_tok], 0.0, set())]\n",
    "\n",
    "    for _ in range(max_out_len):\n",
    "        all_candidates = []\n",
    "        for tokens, score, found_required in beams:\n",
    "            # Jika beam sudah mencapai token <end>, simpan dan lanjutkan ke beam berikutnya\n",
    "            if tokens[-1] == end_tok:\n",
    "                all_candidates.append((tokens, score, found_required))\n",
    "                continue\n",
    "\n",
    "            dec_in = pad_sequences([tokens], maxlen=max_dec_len, padding=\"post\")\n",
    "            preds = model.predict([seq_enc, dec_in], verbose=0)\n",
    "            log_probs = np.log(preds[0, len(tokens)-1, :] + 1e-9)\n",
    "\n",
    "            # Penalti untuk repetisi token\n",
    "            token_counts = Counter(tokens)\n",
    "            for token_id, cnt in token_counts.items():\n",
    "                if token_id in (start_tok, end_tok, 0): continue\n",
    "                log_probs[token_id] -= REPETITION_PENALTY * cnt\n",
    "\n",
    "            # Penalti untuk n-gram berulang\n",
    "            if len(tokens) >= NO_REPEAT_NGRAM_SIZE:\n",
    "                current_ngram_prefix = tuple(tokens[-(NO_REPEAT_NGRAM_SIZE-1):])\n",
    "                history_ngrams = {tuple(tokens[i:i+NO_REPEAT_NGRAM_SIZE]) for i in range(len(tokens) - NO_REPEAT_NGRAM_SIZE + 1)}\n",
    "                for token_id in range(len(log_probs)):\n",
    "                    if current_ngram_prefix + (token_id,) in history_ngrams:\n",
    "                        log_probs[token_id] = -np.inf\n",
    "\n",
    "            # Ambil top-k kandidat\n",
    "            top_k_indices = np.argsort(log_probs)[-top_k:]\n",
    "            for idx in top_k_indices:\n",
    "                new_tokens = tokens + [idx]\n",
    "                new_score = score + log_probs[idx]\n",
    "                new_found_required = found_required.copy()\n",
    "                if idx in required_ids:\n",
    "                    new_found_required.add(idx)\n",
    "                all_candidates.append((new_tokens, new_score, new_found_required))\n",
    "\n",
    "        if not all_candidates:\n",
    "            break\n",
    "\n",
    "        # Simpan hanya beam terbaik berdasarkan skor yang dinormalisasi oleh penalti panjang\n",
    "        ordered = sorted(all_candidates, key=lambda x: x[1] / length_penalty(len(x[0])), reverse=True)\n",
    "        beams = ordered[:beam_width]\n",
    "\n",
    "        # Hentikan jika semua beam berakhir\n",
    "        if all(b[0][-1] == end_tok for b in beams):\n",
    "            break\n",
    "\n",
    "    # Penilaian akhir beam dengan penalti untuk token wajib yang hilang\n",
    "    def final_score(beam):\n",
    "        tokens, score, found = beam\n",
    "        penalty = len(required_ids - found) * REQUIRED_TOKEN_PENALTY\n",
    "        return (score / length_penalty(len(tokens))) + penalty\n",
    "\n",
    "    best_beam = max(beams, key=final_score)\n",
    "    return post_process_sequence(best_beam[0])\n",
    "\n",
    "print(\"\\n--- Setup selesai. Model siap digunakan untuk inferensi. ---\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T02:33:18.790794Z",
     "iopub.status.busy": "2025-11-03T02:33:18.790371Z",
     "iopub.status.idle": "2025-11-03T02:33:19.920072Z",
     "shell.execute_reply": "2025-11-03T02:33:19.919281Z",
     "shell.execute_reply.started": "2025-11-03T02:33:18.790777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-11-03 02:33:18--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 99.83.220.108, 35.71.179.82, 13.248.244.96, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|99.83.220.108|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 13921656 (13M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-amd64.zip’\n",
      "\n",
      "ngrok-stable-linux- 100%[===================>]  13.28M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2025-11-03 02:33:19 (99.3 MB/s) - ‘ngrok-stable-linux-amd64.zip’ saved [13921656/13921656]\n",
      "\n",
      "Archive:  ngrok-stable-linux-amd64.zip\n",
      "  inflating: ngrok                   \n",
      "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
     ]
    }
   ],
   "source": [
    "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
    "!unzip ngrok-stable-linux-amd64.zip\n",
    "!chmod +x ngrok\n",
    "!./ngrok authtoken 34AycPhBQWeAvdotE3zBxd1TT1G_7oLroAXm1hnup3koR2p7f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T02:33:19.921364Z",
     "iopub.status.busy": "2025-11-03T02:33:19.921067Z",
     "iopub.status.idle": "2025-11-03T02:33:24.290223Z",
     "shell.execute_reply": "2025-11-03T02:33:24.289128Z",
     "shell.execute_reply.started": "2025-11-03T02:33:19.921332Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: ngrok: command not found\n",
      "Requirement already satisfied: fastapi in /usr/local/lib/python3.11/dist-packages (0.116.1)\n",
      "Requirement already satisfied: uvicorn in /usr/local/lib/python3.11/dist-packages (0.35.0)\n",
      "Collecting pyngrok\n",
      "  Downloading pyngrok-7.4.1-py3-none-any.whl.metadata (8.1 kB)\n",
      "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
      "Requirement already satisfied: starlette<0.48.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (0.47.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.12.0a1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.3.0)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.37.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.37.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.48.0,>=0.40.0->fastapi) (4.11.0)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.48.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Downloading pyngrok-7.4.1-py3-none-any.whl (25 kB)\n",
      "Installing collected packages: pyngrok\n",
      "Successfully installed pyngrok-7.4.1\n"
     ]
    }
   ],
   "source": [
    "!ngrok authtoken 34AycPhBQWeAvdotE3zBxd1TT1G_7oLroAXm1hnup3koR2p7f\n",
    "!pip install fastapi uvicorn pyngrok nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-03T02:33:28.098661Z",
     "iopub.status.busy": "2025-11-03T02:33:28.098364Z",
     "iopub.status.idle": "2025-11-03T02:37:01.006345Z",
     "shell.execute_reply": "2025-11-03T02:37:01.005784Z",
     "shell.execute_reply.started": "2025-11-03T02:33:28.098638Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Public URL: https://noncapricious-goutily-jurnee.ngrok-free.dev\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [37]\n",
      "INFO:     Waiting for application startup.\n",
      "INFO:     Application startup complete.\n",
      "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762137295.717183     101 service.cc:148] XLA service 0x7a527c0457d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762137295.717949     101 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762137295.717970     101 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762137296.181950     101 cuda_dnn.cc:529] Loaded cuDNN version 90300\n",
      "I0000 00:00:1762137297.342763     101 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     182.253.48.126:0 - \"POST /predict HTTP/1.1\" 200 OK\n",
      "INFO:     182.253.48.126:0 - \"POST /predict HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Shutting down\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO:     Application shutdown complete.\n",
      "INFO:     Finished server process [37]\n",
      "Traceback (most recent call last):\n",
      "  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
      "    ColabKernelApp.launch_instance()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/usr/local/lib/python3.11/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/usr/lib/python3.11/asyncio/base_events.py\", line 1921, in _run_once\n",
      "    handle = self._ready.popleft()\n",
      "             ^^^^^^^^^^^^^^^^^^^^^\n",
      "IndexError: pop from an empty deque\n"
     ]
    }
   ],
   "source": [
    "# --- Setup Lingkungan dan Impor Library ---\n",
    "import nest_asyncio \n",
    "from fastapi import FastAPI  \n",
    "from pydantic import BaseModel \n",
    "from pyngrok import ngrok\n",
    "\n",
    "# --- Inisialisasi Aplikasi FastAPI ---\n",
    "app = FastAPI()\n",
    "\n",
    "class InputText(BaseModel):\n",
    "    # Mendefinisikan struktur data input yang diharapkan dari klien API\n",
    "    # Klien harus mengirimkan JSON dengan key \"text\" yang berisi string\n",
    "    text: str\n",
    "\n",
    "# --- Endpoint API untuk Prediksi ---\n",
    "@app.post(\"/predict\")  # Mendefinisikan endpoint yang merespons permintaan HTTP POST di jalur /predict\n",
    "def predict_text(data: InputText):\n",
    "    # Menerima data input yang sudah divalidasi oleh InputText\n",
    "    input_text = data.text.strip()\n",
    "    \n",
    "    # Validasi input kosong\n",
    "    if not input_text:\n",
    "        return {\"error\": \"Input kosong\"}\n",
    "\n",
    "    try:\n",
    "        # Memanggil fungsi decoding model Seq2Seq yang telah dilatih\n",
    "        output = beam_search_decoder(input_text)\n",
    "        \n",
    "        # Mengembalikan hasil prediksi dalam format JSON ke klien\n",
    "        return {\"input\": input_text, \"output\": output}\n",
    "    \n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "# --- Konfigurasi Server dan Tunneling ---\n",
    "port = 8000  \n",
    "\n",
    "# Menggunakan library pyngrok untuk membuat tunnel\n",
    "ngrok_tunnel = ngrok.connect(port)\n",
    "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
    "\n",
    "# Menjalankan Server Uvicorn\n",
    "nest_asyncio.apply()  # Untuk kompatibilitas lingkungan notebook\n",
    "import uvicorn \n",
    "# Menjalankan aplikasi FastAPI di server Uvicorn\n",
    "uvicorn.run(app, host=\"0.0.0.0\", port=port)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8529504,
     "sourceId": 13438138,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 478249,
     "modelInstanceId": 462471,
     "sourceId": 615353,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
